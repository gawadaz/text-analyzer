---
description: This document describes the minimal DynamoDB table structure for the Text Analyzer MVP.
applyTo: **
---

# DynamoDB Structure – MVP (Text Analyzer)

## Purpose
This document describes the **minimal DynamoDB table structure** used by the Text Analyzer MVP.

The table stores:
- File upload metadata
- Processing status
- Analysis results inline
- Error information (if processing fails)

There is **no user management yet**.
An `ownerId` represents an anonymous or future-authenticated user.

---

## Table Overview

- **Table name**: `text-analyzer-history`
- **Design**: Single-table design
- **Primary Key**:
  - `PK` (partition key, string)
  - `SK` (sort key, string)

Each row is an **item**.  
Different item types may exist in the same table. The MVP now includes **File metadata items** and **Owner history items**.

---

## Item Type: File Metadata (MVP – required)

This is the **source of truth** for a single uploaded file and its analysis lifecycle.

### Primary Keys
PK = FILE#<fileId>
SK = META


---

## Required Attributes

### Identity
- `fileId` (string)  
  Unique identifier for the file.  
  Generated by the backend (UUID / ULID) during presign request.

- `ownerId` (string)  
  Anonymous or future user identifier.  
  No authentication assumptions should be made.

---

### S3 Upload Information
- `s3Bucket` (string)  
  S3 bucket where the file is stored.

- `s3Key` (string)  
  Full S3 object key for the uploaded file.

- `originalFileName` (string)  
  File name as provided by the client.

---

### Processing State
- `status` (string enum)  
  One of:
  - `PENDING` – presign created, upload not finished
  - `IN_PROGRESS` – worker is analyzing the file
  - `COMPLETED` – analysis finished successfully
  - `FAILED` – analysis failed

- `createdAt` (number)  
  Epoch timestamp (milliseconds) when the file record was created.

- `updatedAt` (number)  
  Epoch timestamp (milliseconds) of the last state change.

---

### Results (choose ONE approach)

#### Option A – Store results inline (small payloads)
- `result` (map)
  - Example:
    ```json
    {
      "totalWords": 1200,
      "uniqueWords": 340,
      "avgWordLength": 4.7,
      "top10Words": [
        {"word": "the", "count": 80},
        {"word": "and", "count": 45}
      ]
    }
    ```

---

### Error Handling (optional)
- `errorMessage` (string)  
  Human-readable error message.  
  Only present when `status = FAILED`.

---

## Item Type: Owner History (MVP – required)

This item supports listing files by `ownerId` without a GSI.

### Primary Keys
PK = OWNER#<ownerId>
SK = FILE#<fileId>

### Required Attributes
- `fileId` (string)
- `ownerId` (string)
- `s3Bucket` (string)
- `s3Key` (string)
- `originalFileName` (string)
- `status` (string enum: `PENDING`, `IN_PROGRESS`, `COMPLETED`, `FAILED`)
- `createdAt` (number, epoch ms)
- `updatedAt` (number, epoch ms)

### Error Handling (optional)
- `errorMessage` (string)

---

---

## Idempotency Rules (IMPORTANT)

- `fileId` uniquely identifies a processing job.
- Workers **must check the item status before processing**.
- If `status = COMPLETED`, the worker must exit without reprocessing.
- Updates to `IN_PROGRESS` should be done using conditional updates to avoid duplicate work.

---

## Access Patterns (MVP)

The system must support:

1. **Get file status by fileId**
   - `GetItem` using:
     ```
     PK = FILE#<fileId>
     SK = META
     ```

2. **Update status during processing**
   - Conditional `UpdateItem` based on current status.

3. **List files by ownerId**
  - `Query` using:
    ```
    PK = OWNER#<ownerId>
    ```


---

## Constraints for Copilot / AI Agent

- ❌ Do not introduce GSIs unless explicitly requested.
- ❌ Do not introduce additional tables.
- ❌ Do not assume authentication or authorization.
- ✅ Keep schema minimal and explicit.
- ✅ Prefer clarity and predictability over optimization.

---

## Future Extensions (NOT part of MVP)
- User authentication (Cognito)
- History items per owner
- TTL for automatic cleanup
- Retry counters and processing leases
- GSI for owner-based queries

These should NOT be implemented unless explicitly requested.
